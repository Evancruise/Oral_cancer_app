from flask import Flask, render_template, request, redirect, session, url_for, jsonify, send_from_directory, abort
from linebot import LineBotApi, WebhookHandler
from linebot.models import (
    MessageEvent, TextMessage, TextSendMessage, ImageMessage, ImageSendMessage, 
    TemplateSendMessage, ButtonsTemplate, PostbackAction, PostbackEvent,
    URIAction, ButtonsTemplate
)
from linebot.exceptions import InvalidSignatureError
from app import save_record, draw_predictions, generate_prompt_response, transform_image_to_tensor
from DINO_v2_self.model import YOLOv9_M4, DINOv2TokenSegmentation
import cv2
import torch
import os
import requests
from pyngrok import ngrok
import webbrowser
import uuid
from DINO_v2_self.config import Config
import torchvision.ops as ops
# from line_infer import handle_image
import psutil

def kill_existing_ngrok():
    for proc in psutil.process_iter(['pid', 'name']):
        try:
            if 'ngrok' in proc.info['name'].lower():
                print(f"ğŸ”ª æ®ºæ‰èˆŠçš„ ngrokï¼šPID {proc.info['pid']}")
                proc.kill()
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue

# === Initialization ===
app = Flask(__name__)

all_config = Config()

liff_id = all_config.liff_id
user_id = all_config.user_id
line_channel_access_token = all_config.line_channel_access_token
web_url = all_config.web_url
channel_id = all_config.channel_id
handler = all_config.handler
line_bot_api = all_config.line_bot_api
device = all_config.device
num_classes = all_config.num_classes
class_names = all_config.class_names

IMAGE_DIR = "static/images"
MODEL_DIR = "static/models"
ANNOT_DIR = "annotations"
RESULT_DIR = "static/results"
UPLOAD_DIR = "static/uploads"
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp'}

os.makedirs(IMAGE_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(ANNOT_DIR, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)

# å¾ .env æˆ– config.json è¼‰å…¥è¨­å®š
def load_config():
    if os.path.exists("config.json"):
        with open("config.json", "r") as f:
            config = json.load(f)
    else:
        config = {
            "channel_access_token": line_channel_access_token,
            "liff_id": liff_id,
            "channel_id": channel_id,
            "port": 5000,
        }
    return config

def update_liff_endpoint(liff_id, access_token, new_url):
    url = f"https://api.line.me/liff/v1/apps/{liff_id}"

    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }

    data = {
        "view": {
            "type": "full",
            "url": new_url
        }
    }

    response = requests.put(url, headers=headers, json=data)

    if response.status_code == 200:
        print(f"âœ… LIFF endpoint å·²æˆåŠŸæ›´æ–°ç‚º: {new_url}")
    else:
        print(f"âŒ æ›´æ–°å¤±æ•—: {response.status_code}")
        print(response.text)

def update_line_webhook_url(new_url):
    print(f"Updating LINE webhook URL to: {new_url}")
    url = "https://api.line.me/v1/bot/channel/webhook/endpoint"
    headers = {
        "Authorization": f"Bearer {line_channel_access_token}",
        "Content-Type": "application/json"
    }
    data = {
        "endpoint": new_url
    }
    response = requests.put(url, json=data, headers=headers)
    if response.status_code == 200:
        print("âœ… LINE webhook URL updated successfully!")
    else:
        print(f"âŒ Failed to update LINE webhook URL: {response.status_code}")
        print(response.text)

# è‡ªå‹•å•Ÿå‹• ngrok ä¸¦å›å‚³ URL
def start_ngrok(port=5000):
    public_url = ngrok.connect(port, bind_tls=True)
    print(f"ğŸŒ ngrok å•Ÿå‹•æˆåŠŸ: {public_url}")
    return public_url

@app.route("/callback", methods=['POST'])
def callback():
    print("[DEBUG] /callback called")
    signature = request.headers.get('X-Line-Signature', None)
    if signature is None:
        print("No X-Line-Signature header")
        abort(400)
    body = request.get_data(as_text=True)
    print(f"[DEBUG] Body: {body}")
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("Invalid signature error")
        abort(400)
    except Exception as e:
        print(f"Handler error: {e}")
        abort(500)
    return "OK", 200

# === Model inference API
def send_liff_button(user_id, liff_url):
    line_bot_api.push_message(
        user_id,
        TemplateSendMessage(
            alt_text="é»é¸é€²å…¥å£è…”ç™Œè¨ºæ–·å·¥å…·",
            template=ButtonsTemplate(
                title="AI å£è…”ç™Œè¨ºæ–·",
                text="è«‹é»ä¸‹æ–¹æŒ‰éˆ•é–‹å•Ÿåœ–åƒè¨ºæ–·é é¢",
                actions=[
                    URIAction(
                        label="é–‹å•Ÿè¨ºæ–·é ",
                        uri=liff_url
                    )
                ]
            )
        )
    )

@app.route("/inference", methods=["POST"])
def inference():

    image_name = request.form.get("image")
    model_name = request.form.get("model")

    print("image_name:", image_name, " | model_name:", model_name)

    # session["image_name"] = image_name
    # session["model_name"] = model_name

    img_path = os.path.join(UPLOAD_DIR, image_name)
    # image, pred_mask = infer_single_image_for_web(img_path)

    orig_img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)
    img_tensor = transform_image_to_tensor(img_rgb).unsqueeze(0).to(device)  # å‡è¨­ä½ æœ‰é€™å€‹è½‰æ›

    if model_name.split("_")[0] == "yolov9":
        model = YOLOv9_M4(num_classes=num_classes).to(device)
            # æ¨è«–å–®å¼µåœ–ç‰‡
        with torch.no_grad():
            model.eval()
            outputs = model(img_tensor)  # List[dict] æ ¼å¼
            
            boxes_list, scores_list = [], []

            for level in outputs:
                boxes = level["boxes"][0]               # (N, 4)
                obj = level["obj"][0].squeeze()         # (N,)
                cls_logits = level["cls"][0]            # (N, num_classes)

                # è½‰æˆæ©Ÿç‡å¾Œï¼Œå–æ¯å€‹ row æœ€å¤§å€¼ç•¶ä½œé æ¸¬é¡åˆ¥èˆ‡ score
                cls_scores = cls_logits.sigmoid()       # (N, num_classes)
                max_scores, cls_indices = cls_scores.max(dim=1)  # (N,), (N,)

                conf = obj * max_scores                 # (N,)ï¼ŒYOLO é¢¨æ ¼ conf è¨ˆç®—
                mask = conf > 0.3                       # ç¯©æ‰å¤ªä½çš„ä¿¡å¿ƒé æ¸¬

                boxes = boxes[mask]
                cls_indices = cls_indices[mask]
                conf = conf[mask]

                if len(boxes) > 0:
                    scores = torch.stack([conf, cls_indices.float()], dim=1)  # (N, 2)
                    boxes_list.append(boxes)
                    scores_list.append(scores)

            if boxes_list:
                all_boxes = torch.cat(boxes_list, dim=0)       # [N, 4]
                all_scores = torch.cat(scores_list, dim=0)     # [N, 2] â†’ conf, class_id

                keep = ops.nms(all_boxes, all_scores[:, 0], iou_threshold=0.5)

                final_boxes = all_boxes[keep]                  # [M, 4]
                final_confs = all_scores[keep][:, 0]           # [M]
                final_classes = all_scores[keep][:, 1]         # [M]

                # â¤ concat [x1,y1,x2,y2,conf,class_id]
                preds = torch.cat([
                    final_boxes,
                    final_confs.unsqueeze(1),
                    final_classes.unsqueeze(1)
                ], dim=1)   # [M, 6]
            else:
                preds = torch.empty((0, 6))

            # ç¹ªè£½é æ¸¬æ¡†
            img_with_boxes = draw_predictions(orig_img.copy(), preds.cpu(), class_names, 0.3)

            # å„²å­˜åœ–ç‰‡
            result_filename = f"result_{image_name}"
            result_path = os.path.join(RESULT_DIR, result_filename)
            cv2.imwrite(result_path, img_with_boxes)

            # ...æ¨è«–çµæœ preds = [x1,y1,x2,y2,class_id]
            if preds.size(0) > 0:
                # åŠ ä¸Š conf
                preds_with_conf = torch.cat([
                    preds[:, :4],
                    all_scores[keep][:, 0].unsqueeze(1),  # confidence
                    preds[:, 4].unsqueeze(1)  # class_id
                ], dim=1)
                chatbot_response = generate_prompt_response(preds_with_conf.cpu().numpy(), class_names)
            else:
                chatbot_response = "æœªåµæ¸¬åˆ°ç—…ç¶ï¼Œè«‹ç¢ºèªåœ–åƒå“è³ªæˆ–é‡è©¦ã€‚"

        return jsonify({
            "filename": image_name,
            "result_img_url": RESULT_DIR + "/" + result_filename,
            "image_index": image_name,
            "model_index": model_name,
            "diagnosis_text": chatbot_response
        })
        
    elif model_name.split("_")[0] == "dinov2":
        model = DINOv2TokenSegmentation(num_classes=num_classes).to(device)

        with torch.no_grad():
            model.eval()
            outputs = model(img_tensor)  # List[dict] æ ¼å¼

            # è™•ç†é æ¸¬è¼¸å‡º
            pred_mask = outputs["sem_seg"][0]  # [C, H, W]
            pred_label = torch.argmax(pred_mask, dim=0).cpu().numpy().astype("uint8")  # [H, W]

            # ä¸Šè‰²ï¼ˆå¯é¸ï¼‰
            color_map = get_pascal_colormap(num_classes=21)  # æˆ–ä½ è‡ªå·±çš„ palette
            pred_color = color_map[pred_label]  # [H, W, 3]

            # å„²å­˜åœ–ç‰‡
            result_filename = f"seg_{image_name}"
            result_path = os.path.join(RESULT_DIR, result_filename)
            imageio.imwrite(result_path, pred_color)

            return jsonify({
                "filename": image_name,
                "result_img_url": RESULT_DIR + "/" + result_filename,  # é€™è·¯å¾‘è¦å°æ‡‰ä½ çš„éœæ…‹è³‡æ–™å¤¾è¨­ç½®
                "image_index": image_name,
                "model_index": model_name
            })

# === åœ–ç‰‡è¨Šæ¯è™•ç† ===
# Line Bot API
@app.route("/line_webhook", methods=["POST"])
def line_webhook():
    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        print("Exception in handler.handle:", e)
        abort(500)

    return 'OK'

def handle_image(event, line_bot_api):
    message_id = event.message.id
    user_id = event.source.user_id

    filename = f"{uuid.uuid4().hex}.jpg"
    img_path = os.path.join(UPLOAD_DIR, filename)
    result_path = os.path.join(RESULT_DIR, f"result_{filename}")

    image_content = line_bot_api.get_message_content(message_id)
    with open(img_path, 'wb') as f:
        for chunk in image_content.iter_content():
            f.write(chunk)

    # === æ¨è«–é–‹å§‹ ===
    orig_img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)
    img_tensor = transform_image_to_tensor(img_rgb).unsqueeze(0).to(device)

    print("Load model Yolov9_M4...")
    model = YOLOv9_M4(num_classes=num_classes).to(device)
    model.eval()

    with torch.no_grad():

        print("Start inferencing...")
        outputs = model(img_tensor)
        print("Outputs:", outputs)

        boxes_list, scores_list = [], []
        for level in outputs:
            boxes = level["boxes"][0]               # (N, 4)
            obj = level["obj"][0].squeeze()         # (N,)
            cls_logits = level["cls"][0]            # (N, num_classes)
            # è½‰æˆæ©Ÿç‡å¾Œï¼Œå–æ¯å€‹ row æœ€å¤§å€¼ç•¶ä½œé æ¸¬é¡åˆ¥èˆ‡ score
            cls_scores = cls_logits.sigmoid()       # (N, num_classes)
            max_scores, cls_indices = cls_scores.max(dim=1)  # (N,), (N,)
            conf = obj * max_scores                 # (N,)ï¼ŒYOLO é¢¨æ ¼ conf è¨ˆç®—
            mask = conf > 0.3                       # ç¯©æ‰å¤ªä½çš„ä¿¡å¿ƒé æ¸¬
            boxes = boxes[mask]
            cls_indices = cls_indices[mask]
            conf = conf[mask]
            if len(boxes) > 0:
                scores = torch.stack([conf, cls_indices.float()], dim=1)  # (N, 2)
                boxes_list.append(boxes)
                scores_list.append(scores)

        if boxes_list:
            all_boxes = torch.cat(boxes_list, dim=0)       # [N, 4]
            all_scores = torch.cat(scores_list, dim=0)     # [N, 2] â†’ conf, class_id
            keep = ops.nms(all_boxes, all_scores[:, 0], iou_threshold=0.5)
            final_boxes = all_boxes[keep]                  # [M, 4]
            final_confs = all_scores[keep][:, 0]           # [M]
            final_classes = all_scores[keep][:, 1]         # [M]
            # â¤ concat [x1,y1,x2,y2,conf,class_id]
            preds = torch.cat([
                final_boxes,
                final_confs.unsqueeze(1),
                final_classes.unsqueeze(1)
            ], dim=1)   # [M, 6]
        else:
            preds = torch.empty((0, 6))

    print("Finish inferencing...")

    print("Generating image...")
    # === ç¹ªè£½ & å„²å­˜åœ–ç‰‡ ===
    img_with_boxes = draw_predictions(orig_img.copy(), preds.cpu(), class_names, 0.3)
    cv2.imwrite(result_path, img_with_boxes)

    print("Generating diagnosis...")
    # === è¨ºæ–·æ–‡å­— ===
    '''
    if preds.size(0) > 0:
        preds_with_conf = torch.cat([
            preds[:, :4],
            all_scores[keep][:, 0].unsqueeze(1),
            preds[:, 4].unsqueeze(1)
        ], dim=1)
        chatbot_response = generate_prompt_response(preds_with_conf.cpu().numpy(), class_names)
    else:
        chatbot_response = "æœªåµæ¸¬åˆ°ç—…ç¶ï¼Œè«‹ç¢ºèªåœ–åƒå“è³ªæˆ–é‡è©¦ã€‚"
    '''

    result_url = f"https://{web_url}/{result_path}"

    line_bot_api.reply_message(
        event.reply_token,
        [
            ImageSendMessage(
                original_content_url=result_url,
                preview_image_url=result_url
            ),
            TextSendMessage(text=chatbot_response)
        ]
    )

@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    print("Into handle_image_message function...")
    handle_image(event, line_bot_api)

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_text = event.message.text

    # ä½¿ç”¨è€…è¼¸å…¥ "å¹«æˆ‘è¨ºæ–· abc.jpg"
    if "è¨ºæ–·" in user_text:
        image_name = user_text.replace("å¹«æˆ‘è¨ºæ–·", "").strip()

        img_path = os.path.join(IMAGE_DIR, image_name)

        image, pred_mask = infer_single_image_for_web(img_path)
        
        if pred_mask is None:
            reply_text = "ç„¡æ³•è¾¨è­˜åœ–ç‰‡ï¼Œè«‹ç¢ºèªåœ–ç‰‡æ ¼å¼æˆ–å…§å®¹"
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=reply_text)
            )
            return
        
        result_filename = f"result_{image_name}"
        result_path = os.path.join(RESULT_DIR, result_filename)
        image.save(result_path)

        reply_text = f"å·²å®Œæˆè¾¨è­˜ âœ…\nçµæœåœ–é€£çµ:\nhttps://{web_url}/{result_path}"
    else:
        reply_text = "è«‹è¼¸å…¥ï¼šå¹«æˆ‘è¨ºæ–· xxx.jpg"

    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=reply_text)
    )

@handler.add(PostbackEvent)
def handle_postback(event):
    data = event.postback.data
    user_id = event.source.user_id

    if data == "action=query_record":
        # ğŸ“‹ æŸ¥è©¢è©²ä½¿ç”¨è€…æœ€è¿‘ç¯©æª¢ç´€éŒ„ï¼ˆå‡è¨­ä½ æœ‰ç´€éŒ„åˆ° DBï¼‰
        record = query_user_latest_record(user_id)

        reply_text = (
            f"ğŸ“‹ ä½ çš„æœ€æ–°ç¯©æª¢ç´€éŒ„ï¼š\n"
            f"- æª”åï¼š{record['filename']}\n"
            f"- æ¨¡å‹ï¼š{record['model']}\n"
            f"- çµæœï¼š{record['result']}\n"
            f"- æ™‚é–“ï¼š{record['timestamp']}"
        )

        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=reply_text)
        )
    elif data == "action=go_home":
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text="ğŸ  ä½ å·²å›åˆ°ä¸»é¸å–®ï¼Œå¯ä»¥å†æ¬¡ä¸Šå‚³åœ–ç‰‡é€²è¡Œç¯©æª¢ã€‚")
        )

# LIFF API
@app.route('/liff_index')
def liff_index():
    # return render_template('liff_index.html')
    model_dict = []
    for model in os.listdir(MODEL_DIR):
        model_dict.append(model.split("_")[0])

    return render_template(
        "liff_index.html",
        model_dict=model_dict,
        liff_id=liff_id)

@app.route("/liff_infer", methods=["POST"])
def liff_infer():
    chatbot_response = ""

    user_id = request.form["userId"]
    file = request.files["image"]
    modelid = request.files["modelId"]

    filename = f"{uuid.uuid4().hex}.jpg"
    img_path = os.path.join(IMAGE_DIR, filename)
    file.save(img_path)
    
    if modelid == "yolov9":
        model = YOLOv9_M4(num_classes=num_classes).to(device)
        
        # æ¨è«–å–®å¼µåœ–ç‰‡
        with torch.no_grad():
            model.eval()
            outputs = model(img_tensor)  # List[dict] æ ¼å¼
            
            boxes_list, scores_list = [], []

            for level in outputs:
                boxes = level["boxes"][0]               # (N, 4)
                obj = level["obj"][0].squeeze()         # (N,)
                cls_logits = level["cls"][0]            # (N, num_classes)

                # è½‰æˆæ©Ÿç‡å¾Œï¼Œå–æ¯å€‹ row æœ€å¤§å€¼ç•¶ä½œé æ¸¬é¡åˆ¥èˆ‡ score
                cls_scores = cls_logits.sigmoid()       # (N, num_classes)
                max_scores, cls_indices = cls_scores.max(dim=1)  # (N,), (N,)

                conf = obj * max_scores                 # (N,)ï¼ŒYOLO é¢¨æ ¼ conf è¨ˆç®—
                mask = conf > 0.3                       # ç¯©æ‰å¤ªä½çš„ä¿¡å¿ƒé æ¸¬

                boxes = boxes[mask]
                cls_indices = cls_indices[mask]
                conf = conf[mask]

                if len(boxes) > 0:
                    scores = torch.stack([conf, cls_indices.float()], dim=1)  # (N, 2)
                    boxes_list.append(boxes)
                    scores_list.append(scores)

            if boxes_list:
                all_boxes = torch.cat(boxes_list, dim=0)       # [N, 4]
                all_scores = torch.cat(scores_list, dim=0)     # [N, 2] â†’ conf, class_id

                keep = ops.nms(all_boxes, all_scores[:, 0], iou_threshold=0.5)

                final_boxes = all_boxes[keep]                  # [M, 4]
                final_confs = all_scores[keep][:, 0]           # [M]
                final_classes = all_scores[keep][:, 1]         # [M]

                # â¤ concat [x1,y1,x2,y2,conf,class_id]
                preds = torch.cat([
                    final_boxes,
                    final_confs.unsqueeze(1),
                    final_classes.unsqueeze(1)
                ], dim=1)   # [M, 6]
            else:
                preds = torch.empty((0, 6))

            # ç¹ªè£½é æ¸¬æ¡†
            img_with_boxes = draw_predictions(orig_img.copy(), preds.cpu(), class_names, 0.3)

            # å„²å­˜åœ–ç‰‡
            result_filename = f"result_{image_name}"
            result_path = os.path.join(RESULT_DIR, result_filename)
            cv2.imwrite(result_path, img_with_boxes)

            # ...æ¨è«–çµæœ preds = [x1,y1,x2,y2,class_id]
            if preds.size(0) > 0:
                # åŠ ä¸Š conf
                preds_with_conf = torch.cat([
                    preds[:, :4],
                    all_scores[keep][:, 0].unsqueeze(1),  # confidence
                    preds[:, 4].unsqueeze(1)  # class_id
                ], dim=1)
                chatbot_response = generate_prompt_response(preds_with_conf.cpu().numpy(), class_names)
            else:
                chatbot_response = "æœªåµæ¸¬åˆ°ç—…ç¶ï¼Œè«‹ç¢ºèªåœ–åƒå“è³ªæˆ–é‡è©¦ã€‚"

    elif modelid == "dinov2":    
        model = DINOv2TokenSegmentation(num_classes=num_classes).to(device)

        with torch.no_grad():
            model.eval()
            outputs = model(img_tensor)  # List[dict] æ ¼å¼

            # è™•ç†é æ¸¬è¼¸å‡º
            pred_mask = outputs["sem_seg"][0]  # [C, H, W]
            pred_label = torch.argmax(pred_mask, dim=0).cpu().numpy().astype("uint8")  # [H, W]

            # ä¸Šè‰²ï¼ˆå¯é¸ï¼‰
            color_map = get_pascal_colormap(num_classes=3)  # æˆ–ä½ è‡ªå·±çš„ palette
            pred_color = color_map[pred_label]  # [H, W, 3]

            # å„²å­˜åœ–ç‰‡
            result_filename = f"seg_{image_name}"
            result_path = os.path.join(RESULT_DIR, result_filename)
            imageio.imwrite(result_path, pred_color)

    # å„²å­˜è¨˜éŒ„
    save_record(user_id, filename, modelname=modelid, result=chatbot_response)

    return jsonify({
        "result_img_url": f"/{result_path}",
        "text": chatbot_response
    })

# === æ¸¬è©¦ç”¨ç¶²é  ===
@app.route('/')
def index():
    # return render_template('liff_index.html')
    model_dict = []
    for model in os.listdir(MODEL_DIR):
        model_dict.append(model.split("_")[0])

    return render_template(
        "liff_index.html",
        model_dict=model_dict,
        liff_id=liff_id)

#if __name__ == "__main__":
#    app.run(host="0.0.0.0", port=5000, debug=True)

# === Flask Run + ngrok ===
if __name__ == "__main__":
    kill_existing_ngrok()
    config = load_config()

    # ğŸš€ é–‹å•Ÿ ngrok
    public_url = str(ngrok.connect(5000))
    print("ğŸŒ ngrok URL:", public_url)

    # ğŸ›  æ›´æ–° LIFF endpointï¼ˆé¸ç”¨ï¼‰
    update_liff_endpoint(config["liff_id"], config["channel_access_token"], f"{public_url}/liff_index")

    # çµ„æˆæ–°çš„ webhook å®Œæ•´ç¶²å€ï¼ˆåŒ…å«è·¯å¾‘ï¼‰
    new_webhook_url = public_url + "/callback"

    # æ›´æ–° LINE webhook URL
    update_line_webhook_url(new_webhook_url)

    '''
    new_url = f"{public_url}/liff_index"
    update_liff_endpoint(
        liff_id=config["liff_id"],
        access_token=config["channel_access_token"],
        new_url=new_url
    )
    '''

    # å¯é¸ï¼šè‡ªå‹•æ‰“é–‹ç€è¦½å™¨æ¸¬è©¦é é¢
    # webbrowser.open(f"{public_url}/liff_index")
    
    # å¦‚æœä½ è¦è‡ªå‹•é¡¯ç¤ºé€™å€‹ ngrok URLï¼Œæ›´æ–°åˆ°ä¸€å€‹æª”æ¡ˆ
    with open("ngrok_url.txt", "w") as f:
        f.write(str(public_url))

    line_bot_api.push_message(
        user_id,
        TextSendMessage(text=f"æ¨¡å‹å·²æº–å‚™å°±ç·’ï¼è«‹å¹«æˆ‘ä¸Šå‚³ä¸€å¼µå£è…”ç…§ç‰‡")
    )

    app.run(host="0.0.0.0", port=config["port"], debug=True)